input { 
    # used for testing
    # send stuff to logstash via netcat: `echo "foo" | nc localhost 3333`
    tcp { type => "ads-debug" port => 3333 tags => ["beer","http"] }
    tcp { type => "ads-debug" port => 3334 tags => ["beer","http","error"] }

    # these redis lists are written to directly by the app
    redis {
        host => 'localhost' 
        port => 6379
        data_type => 'list' 
        type => 'beer-abs' 
        key => 'adsabs:abs'
        tags => ['beer','abs']
    }
    redis {
        host => 'localhost' 
        port => 6379
        data_type => 'list'
        type => 'beer-api' 
        key => 'adsabs:api'
        tags => ['beer','api']
    }
    redis {
        host => 'localhost'
        port => 6379
        data_type => 'list'
        type => 'beer-search' 
        key => 'adsabs:search'
        tags => ['beer','search']
    }

    # these lists are populated by a beaver daemon reading from log files
    redis {
        host => 'localhost' 
        port => 6379
        data_type => 'list'
        key => 'beer:http'
        tags => ['beer','http']
        type => "_unset" # shippers are responsible for setting event 'type'
    }
    redis {
        host => 'localhost' 
        port => 6379
        data_type => 'list'
        key => 'beer:http-err'
        tags => ['beer','http','error']
        type => "_unset" # shippers are responsible for setting event 'type'
    }
    redis {
        host => 'localhost' 
        port => 6379
        data_type => 'list'
        key => 'solr:logs'
        tags => ['solr']
        type => "_unset" # shippers are responsible for setting event 'type'
    }
}

filter {
    if "beer" in [tags] {
        if "http" in [tags] {
            if "error" in [tags] {
                # should handle both http error logs
                grok {
                    patterns_dir => "/etc/logstash/patterns"
                    match => ["message", "%{GENERICAPACHEERROR}"]
                }
                if [severity] == "debug" {
                    drop {}
                }
            } else {
                grok {
                    patterns_dir => "/etc/logstash/patterns"
                    match => ["message", "%{COMBINDEDWITHRESPTIME}"]
                }
                date {
                    match => [ "timestamp", "dd/MMM/yyyy:HH:mm:ss Z" ]
                }
                grok {
                    patterns_dir => "/etc/logstash/patterns"
                    match => ["path", "\/abs\/%{BIBCODE:bibcode}"]
                    tag_on_failure => []
                }
                # remove quotes from some values
                mutate {
                    gsub => [
                        "referrer", "\"", "",
                        "cookie", "\"", "",
                        "agent", "\"", "",
                        "proxy", "\"", ""
                    ]
                }
                urldecode {
                    all_fields => true
                }
                kv {
                    source => ["qstring"]
                    prefix => "qstring__"
                    field_split => "?&"
                    value_split => "="
                    add_tag => ["kv_applied"]
                }
                kv {
                    source => ["cookie"]
                    prefix => "cookie__"
                    field_split => " "
                    value_split => "="
                    trim => ";"
                    add_tag => ["kv_applied"]
                }
                if [path] =~ "\/api\/" {
                    mutate {
                        add_tag => ["api"]
                    }
                }
                # consolidate classic & labs cookie ids
                if [cookie__NASA_ADS_ID] =~ "\w+" {
                    mutate {
                        add_field => ["user_cookie_id", "%{cookie__NASA_ADS_ID}"]
                    }
                } else if [cookie__NASA_ADSABS2_ID] =~ "\w+" {
                    mutate {
                        add_field => ["user_cookie_id", "%{cookie__NASA_ADSABS2_ID}"]
                    }
                }
                useragent {
                    source => "agent"
                    prefix => "useragent__"
                }
                if [path] =~ "\/static\/" {
                    drop {}
                }
                # prune stuff to keep the ES index size from blowing up
                mutate {
                    remove_field => ["cookie","agent","qstring"]
                }
            }
        }
        # add a hostname field based on ip so that we can reverse dns it
        mutate {
            add_field => ["hostname", "%{client_addr}"]
        }
        dns {
            action => "replace"
            reverse => ["hostname"]
            add_tag => ["dns_reversed"]
        }
        # ... then check if it matches a bot or known "client" software
        if "dns_reversed" in [tags] {
            grok {
                patterns_dir => "/etc/logstash/patterns"
                match => ["hostname", "%{BOTORCLIENT:bot_or_client}"]
                tag_on_failure => []
                add_tag => ["bot"]
            }
        }
    }
    
# TODO: narrow the search to a field so we're not matching against the entire message
# as that's much more likely to trigger UTF-8 exceptions
#    if [message] =~ "Exception" {
#        mutate {
#            add_tag => ["exception"]
#        }
#    }

    if "solr" in [tags] {
        if "exception" in [tags] {
            grok {
                patterns_dir => "/etc/logstash/patterns"
                match => ["message", "(?m)%{SOLREXCEPTION}"]
            }
        } else {
            grok {
                patterns_dir => "/etc/logstash/patterns"
                match => ["message", "%{SOLRLOG}"]
            }
            kv {
                source => ["solr_msg"]
                field_split => " "
                value_split => "="
                trim => "{}"
            }
            kv {
                source => ["params"]
                prefix => "param__"
                field_split => "&"
                value_split => "="
            }
            if [path] =~ "\/ping$" {
                drop {}
            }
            if [path] =~ "\/select$" {
                mutate {
                    add_tag => ["search"]
                }
            }
        }
        date {
            match => [ "timestamp", "yyyy-MM-dd HH:mm:ss" ]
        }
    }

}

output {
    if [type] == "ads-debug" {
        stdout { codec => rubydebug }
    }
    elasticsearch_http {
        host => "localhost"
        manage_template => false
    }
    if "http" in [tags] and "error" not in [tags] {
        # NOTE: keep this next line together so we can dynamically update the config based on 
        # docker container link env variables
        statsd { host => "localhost"
            port => "8125"
            increment => "adsabs.logs.http.response.%{http_status}"
            count => [
                "adsabs.logs.http.bytes", "%{bytes}"
            ]
            timing => [
                "adsabs.logs.http.resptime", "%{resptime}"
            ]
        }
        if "api" in [tags] {
            statsd {
                increment => "adsabs.api.dev_key.{%qstring__dev_key}"
            }
        }
    }
}
