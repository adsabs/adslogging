input { 
    # used for testing
    # send stuff to logstash via netcat: `echo "foo" | nc localhost 3333`
    tcp { type => "ads-debug" port => 3333 tags => ["beer","http"] }
    tcp { type => "ads-debug" port => 3334 tags => ["beer","http","error"] }
    tcp { type => "ads-debug" port => 3335 tags => ["solr"] }

    # these redis lists are written to directly by the app
    redis {
        host => 'localhost' 
        port => 6379
        data_type => 'list' 
        type => 'beer-abs' 
        key => 'adsabs:abs'
        tags => ['beer','abs']
    }
    redis {
        host => 'localhost' 
        port => 6379
        data_type => 'list'
        type => 'beer-api' 
        key => 'adsabs:api'
        tags => ['beer','api']
    }
    redis {
        host => 'localhost'
        port => 6379
        data_type => 'list'
        type => 'beer-search' 
        key => 'adsabs:search'
        tags => ['beer','search']
    }

    # these lists are populated by a beaver daemon reading from log files
    redis {
        host => 'localhost' 
        port => 6379
        data_type => 'list'
        key => 'beer:http'
        tags => ['beer','http']
        type => "_unset" # shippers are responsible for setting event 'type'
    }
    redis {
        host => 'localhost' 
        port => 6379
        data_type => 'list'
        key => 'beer:http-err'
        tags => ['beer','http','error']
        type => "_unset" # shippers are responsible for setting event 'type'
    }
    redis {
        host => 'localhost' 
        port => 6379
        data_type => 'list'
        key => 'solr:logs'
        tags => ['solr']
        type => "_unset" # shippers are responsible for setting event 'type'
    }
}

filter {
    if "beer" in [tags] {
        if "http" in [tags] {
            if "error" in [tags] {
                # should handle both http error logs
                grok {
                    patterns_dir => "/etc/logstash/patterns"
                    match => ["message", "%{GENERICAPACHEERROR}"]
                }
                if [severity] == "debug" {
                    drop {}
                }
            } else {
                grok {
                    patterns_dir => "/etc/logstash/patterns"
                    match => ["message", "%{COMBINDEDWITHRESPTIME}"]
                }
                date {
                    match => [ "timestamp", "dd/MMM/yyyy:HH:mm:ss Z" ]
                }
                grok {
                    patterns_dir => "/etc/logstash/patterns"
                    match => ["path", "\/abs\/%{BIBCODE:bibcode}"]
                    tag_on_failure => []
                }
                # remove quotes from some values
                mutate {
                    gsub => [
                        "referrer", "\"", "",
                        "cookie", "\"", "",
                        "agent", "\"", "",
                        "proxy", "\"", ""
                    ]
                }
                urldecode {
                    all_fields => true
                }
                # uses our custom force_encoding.rb filter plugin
                force_encoding {
                    fields => ["path","qstring","message","referrer"]
                    tag => "_forcedencoding"
                }
                kv {
                    source => ["qstring"]
                    prefix => "qstring__"
                    field_split => "?&"
                    value_split => "="
                    add_tag => ["kv_applied"]
                }
                kv {
                    source => ["cookie"]
                    prefix => "cookie__"
                    field_split => " "
                    value_split => "="
                    trim => ";"
                    add_tag => ["kv_applied"]
                }
                if [path] =~ "\/api\/" {
                    mutate {
                        add_tag => ["api"]
                    }
                }
                # consolidate classic & labs cookie ids
                if [cookie__NASA_ADS_ID] =~ "\w+" {
                    mutate {
                        add_field => ["user_cookie_id", "%{cookie__NASA_ADS_ID}"]
                    }
                } else if [cookie__NASA_ADSABS2_ID] =~ "\w+" {
                    mutate {
                        add_field => ["user_cookie_id", "%{cookie__NASA_ADSABS2_ID}"]
                    }
                }
                useragent {
                    source => "agent"
                    prefix => "useragent__"
                }
                if [path] =~ "\/static\/" {
                    drop {}
                }
                # prune stuff to keep the ES index size from blowing up
                mutate {
                    remove_field => ["cookie","agent","qstring"]
                }
            }
        }
        if "error" not in [tags] {
            # add a hostname field based on ip so that we can reverse dns it
            mutate {
                add_field => ["hostname", "%{client_addr}"]
            }
            dns {
                action => "replace"
                reverse => ["hostname"]
                add_tag => ["dns_reversed"]
            }
            # ... then check if it matches a bot or known "client" software
            if "dns_reversed" in [tags] {
                grok {
                    patterns_dir => "/etc/logstash/patterns"
                    match => ["hostname", "%{BOTORCLIENT:bot_or_client}"]
                    tag_on_failure => []
                    add_tag => ["bot"]
                }
            }
        }
    }
    
    if "solr" in [tags] {
        grok {
            patterns_dir => "/etc/logstash/patterns"
            match => ["message", "%{SOLRLOG}"]
        }
        kv {
            source => ["solr_msg"]
            field_split => " "
            value_split => "="
            trim => "{}"
        }
        kv {
            source => ["params"]
            prefix => "param__"
            field_split => "&"
            value_split => "="
        }
        if [path] =~ "\/ping$" {
            drop {}
        }
        if [path] =~ "\/select$" {
            mutate {
                add_tag => ["search"]
            }
        }
        if [solr_msg] =~ "^Exception" {
            mutate {
                add_tag => ["exception"]
            }
        }
        date {
            match => [ "timestamp", "yyyy-MM-dd HH:mm:ss" ]
            timezone => "America/New_York"
        }
    }
}

output {
    if [type] == "ads-debug" {
        stdout { codec => rubydebug }
    }
    elasticsearch_http {
        host => "localhost"
        manage_template => false
    }
    if "http" in [tags] and "error" not in [tags] {
        # NOTE: keep this next line together so we can dynamically update the config based on 
        # docker container link env variables
        statsd { host => "localhost"
            port => "8125"
            increment => "adsabs.logs.http.response.%{http_status}"
            count => [
                "adsabs.logs.http.bytes", "%{bytes}"
            ]
            timing => [
                "adsabs.logs.http.resptime", "%{resptime}"
            ]
        }
        if "api" in [tags] {
            statsd {
                increment => "adsabs.api.dev_key.{%qstring__dev_key}"
            }
        }
    }
}
